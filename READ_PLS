Perplexity is often used for measuring the usefulness of a language model
(basically a probability distribution over sentence, phrase, words, etc).

When evaluating a LM, a good LM is one that tend to assign higher probabilities
to the test data (predicts very well).

Example for a test set with words W = w_1, w_2, ..., w_n

the perplexity of the model on the test set is

PP(W) = P(w_1, w_2, w_3) ^ (-1/N)

However, perplexity is not a definite way of sdetermining the usefulness of a
language model. A model with low perplexity on a test set may not work eually
well in real world application whose data may not be drawn from the same
distribution as the test set. However, in the lack of efficient means to
evaluate language model, perplexity is a useful metric for comparing language models.

Howeever, in hte lack of efficient means to evaluate language model, Perplexity
is a useful metric for comparing language models.

* Losses.
  - sequence_loss: Loss for a sequence model returning average log-perplexity.
  - sequence_loss_by_example: As above, but not averaging over all examples.

* model_with_buckets: A convenience function to create models with bucketing
    (see the tutorial above for an explanation of why and how to use it).


HIGH ERROR RATE/PERPLEXITY WHEN MISSPELLING IS ADDED IN THE RULES.

The idea is to collect clean text from Tagalog Wikipedia and various News Site that publish reports
in Tagalog. Then, generate the equivalent noisy text using various rules such as:
 - Grouping repeating units
 - Repetition of characters
 - Contraction
 - Accent stylization
 - Phonetic stylization
 - Misspelling

The collection process is fairly easy, since most of the mainstream News Sites in the Philippines has
an archive section. The archive section was scraped using Scrapy and we only scraped the Title, Article and the
URL. For the Tagalog Wikipedia dataset, we used the database dump from November 1, 2016 and extract every article.
Then, we normalized the spaces, the character set used from utf-8 to ascii,
some words that is still in the non-canonical form such as "penge", "meron", "kundi", and etc. We also removed the
articles Location Tag (MANILA, Philippines - <Article>) and the reporter's signature at the end of every article (--FRJ, GMA NEWS) [Articles from new site only].

Then train the parallel clean and noisy text using the Sequence to Sequence Recurrent Neural Network.

- Rules layering
- Remove the anuable rules, just put it in the dictionary.